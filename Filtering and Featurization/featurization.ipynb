{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xrR6NQ1kaYq-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zero Crossing\n",
        "\n",
        "def ZC(data): \n",
        "  n = len(data)\n",
        "  count = 0\n",
        "  \n",
        "  for i in range(n-1):\n",
        "    if (((data[i] > 0) and (data[i+1] < 0)) or ((data[i] < 0) and (data[i+1] > 0))):\n",
        "      count = count + 1\n",
        "\n",
        "  return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Slope Sign Changes\n",
        "\n",
        "def SSC(data): \n",
        "  n = len(data)\n",
        "  count = 0\n",
        "  \n",
        "  for i in range(1, n-1):\n",
        "    if (((data[i] < data[i+1]) and (data[i] < data[i-1])) or ((data[i] > data[i+1]) and (data[i] > data[i-1]))):\n",
        "      count = count + 1\n",
        "\n",
        "  return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iAaYomluZv8E"
      },
      "outputs": [],
      "source": [
        "# Waveform Length\n",
        "\n",
        "def WL(data):\n",
        "  n = len(data)\n",
        "  count = 0\n",
        "\n",
        "  for i in range(n-1):\n",
        "    count += np.abs(data[i+1]-data[i])\n",
        "\n",
        "  return count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RVtAM7AeZqdy"
      },
      "outputs": [],
      "source": [
        "# Willison Amplitude\n",
        "\n",
        "def WA(data, th):\n",
        "  n = len(data)\n",
        "  count = 0\n",
        "  \n",
        "  for i in range(n-1):\n",
        "    if (abs(data[i+1] - data[i]) > th):\n",
        "      count = count + 1\n",
        "\n",
        "  return count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variance \n",
        "\n",
        "def VAR(data):\n",
        "    return np.var(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Skewness\n",
        "\n",
        "def SKEW(data):\n",
        "    return scipy.stats.skew(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kurtosis\n",
        "\n",
        "def KURT(data): \n",
        "    return scipy.stats.kurtosis(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mean\n",
        "\n",
        "def MEAN(data):\n",
        "    return np.mean(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3eANsTUAZ9wV"
      },
      "outputs": [],
      "source": [
        "# Standard Deviation\n",
        "\n",
        "def SD(data):\n",
        "  return np.std(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def MVC(str):\n",
        "    raw1 = np.loadtxt(\"filtereddata/\" + str + \"F1.csv\", delimiter=',')\n",
        "    raw2 = np.loadtxt(\"filtereddata/\" + str + \"F2.csv\", delimiter=',')\n",
        "    raw3 = np.loadtxt(\"filtereddata/\" + str + \"F3.csv\", delimiter=',')\n",
        "    raw4 = np.loadtxt(\"filtereddata/\" + str + \"E1.csv\", delimiter=',')\n",
        "    raw5 = np.loadtxt(\"filtereddata/\" + str + \"E2.csv\", delimiter=',')\n",
        "    raw6 = np.loadtxt(\"filtereddata/\" + str + \"E3.csv\", delimiter=',')\n",
        "\n",
        "    raws = np.abs(np.vstack((raw1, raw2, raw3, raw4, raw5, raw6)))\n",
        "\n",
        "    mvcF = np.max(raws[:,1])\n",
        "    mvcE = np.max(raws[:,3])\n",
        "\n",
        "    return mvcF, mvcE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import\n",
        "for who in [\"Luigi\", \"James\", \"Dailyn\"]:\n",
        "    for what in [\"Drill\", \"Softball\", \"Wood\"]:\n",
        "        for which in [\"Physical\", \"Virtual\"]:\n",
        "\n",
        "          ww = who + \"-\" + which + \"/\"\n",
        "          www = who + \"-\" + which + \"/\" + what\n",
        "          wwwu = who + \"_\" + which + \"_\" + what\n",
        "\n",
        "          raw = np.loadtxt(\"filtereddata/\" + www + \".csv\", delimiter=',')\n",
        "\n",
        "          mvcF, mvcE = MVC(ww)\n",
        "\n",
        "          fcu = np.divide(raw[:,1], mvcF)\n",
        "          ecr = np.divide(raw[:,3], mvcE)\n",
        "\n",
        "          if (who != \"Dailyn\"):\n",
        "            segments = scipy.io.loadmat(\"segments/\" + wwwu + \".mat\")[\"segments\"] # James, Luigi .mat files\n",
        "          else:\n",
        "            segments = np.loadtxt(\"segments/\" + wwwu + \".csv\", delimiter=',', dtype=int) # Dailyn .csv files\n",
        "          \n",
        "          starts = segments[:,0]\n",
        "          ends = segments[:,1]\n",
        "\n",
        "          WA_thresh = 0.06\n",
        "\n",
        "          # Segment \n",
        "          features = np.empty((30,6))\n",
        "\n",
        "          for i in range(30):\n",
        "            start_ind = starts[i]\n",
        "            end_ind = ends[i]\n",
        "            trial_fcu = fcu[start_ind:end_ind]\n",
        "            trial_ecr = ecr[start_ind:end_ind]\n",
        "\n",
        "            wa_fcu = WA(trial_fcu, WA_thresh)\n",
        "            wl_fcu = WL(trial_fcu)\n",
        "            sd_fcu = SD(np.abs(trial_fcu))\n",
        "\n",
        "            wa_ecr = WA(trial_ecr, WA_thresh)\n",
        "            wl_ecr = WL(trial_ecr)\n",
        "            sd_ecr = SD(np.abs(trial_ecr))\n",
        "\n",
        "            features[i,0] = wa_fcu\n",
        "            features[i,1] = wa_ecr\n",
        "\n",
        "            features[i,2] = wl_fcu\n",
        "            features[i,3] = wl_ecr\n",
        "\n",
        "            features[i,4] = sd_fcu\n",
        "            features[i,5] = sd_ecr\n",
        "\n",
        "\n",
        "          out_string = wwwu + \"_fn_features.csv\"\n",
        "          np.savetxt(out_string, features, delimiter=\", \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = True\n",
        "\n",
        "# Physical Virtual \n",
        "# Dailyn James Luigi\n",
        "# Softball Drill Wood\n",
        "\n",
        "for which in [\"Physical\", \"Virtual\"]:\n",
        "    for who in [\"Dailyn\", \"James\", \"Luigi\"]:\n",
        "        for what in [\"Softball\", \"Drill\", \"Wood\"]:\n",
        "        \n",
        "            www = who + \"_\" + which + \"_\" + what + \"_fn_features.csv\"\n",
        "            raw = np.loadtxt(www, delimiter=',')\n",
        "\n",
        "            reord = np.transpose(np.vstack((raw[:,1],raw[:,0],raw[:,3],raw[:,2],raw[:,5],raw[:,4])))\n",
        "            \n",
        "            if f: \n",
        "                all_trials = reord\n",
        "                f = False\n",
        "            else:\n",
        "                all_trials = np.vstack((all_trials, reord))\n",
        "\n",
        "header = \"WA_ECR, WA_FCU, WL_ECR, WL_FCU, SD_ECR, SD_FCU\"\n",
        "np.savetxt(\"JamesFeaturesNorm.csv\", all_trials, delimiter=\", \", header=header)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "594cbcb53b7eb24b01ad1ace3292a9583de43e996a12a214afbcf4f5a5715dd8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
